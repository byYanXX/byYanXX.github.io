---
layout: post
title: "浅谈数据倾斜"
---

## 一、概要

### 1. 什么是数据倾斜？

大量相同的 key 被 partition 分配到了一个分区，导致“一个人累死，其他人闲死”的情况。

### 2. 发生倾斜的症状？

1. 绝大多数的 task 执行的都非常快，个别 task 极慢。
2. 任务在历史周期执行正常，某天突然发生 OOM。

### 3. 定位发生倾斜的位置？

1. 倾斜只会发生在 shuffle 阶段，而触发 shuffle 的算子有：`groupByKey、reduceByKey、aggregateByKey、join、distinct、cogroup、repartiton 等`。针对代码中涉及这些算子的地方进行数据量探查，定位到倾斜位置。
2. 通过 Spark UI 定位到倾斜所在的 stage，及其各个 task 分配的数据量，进而判断是否是因 task 分配不均导致了数据倾斜。

> 如果是 yarn-client 模式提交的，那么本地可以直接从 log 中找到当前运行到了第几个 stage。
>
> 如果是 yarn-cluster 模式提交的，那么从 Spark Web UI 里直接看到运行到了哪个 stage。


## 二、Hive 的数据倾斜

> Hive 的执行是分阶段的，map 处理的数据量差异取决于上一个 stage 的 reduce 输出，所以**解决倾斜问题，就是在思考如何将数据均匀地分配到各个 reduce 中**。

### 1. 常见的倾斜原因
1. key 分布不均；
2. 业务数据本身特性；
3. 模型设计问题；
4. SQL 语句本身导致。

### 2. 倾斜的表现

最朴素的就是任务进度长时间卡在 99%（或100%），而在监控页面中发现只有少量（1个或几个）reduce 子任务因处理的数据量和其他 reduce 差异极大而尚未完成，倾斜的数据量甚至会多出一个数量级。具体倾斜程度可以通过具体 job 的 reducer counter 计数器协助定位。

MR 计数器参见：[https://www.cnblogs.com/codeOfLife/p/5521356.html](https://www.cnblogs.com/codeOfLife/p/5521356.html)

### 3. 解决方案

1. **调参**


### 4. 典型业务场景举例

### 5. 监控预防

## 三、Spark 的数据倾斜

